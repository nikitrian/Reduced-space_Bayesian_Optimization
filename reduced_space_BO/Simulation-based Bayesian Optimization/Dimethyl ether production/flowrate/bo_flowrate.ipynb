{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to create a new conda environment using the environment.yml file\n",
    "```\n",
    "conda env create -f environment.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import utils\n",
    "import tqdm\n",
    "import gpytorch\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, LinearKernel, InducingPointKernel\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "dtype = torch.float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hysys_python.hysys_object_persistence as hop\n",
    "import hysys_gsa_util as hgu\n",
    "import numpy as np\n",
    "import time as ti\n",
    "from IPython.display import clear_output\n",
    "%load_ext line_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_csv('top_inputs.csv')\n",
    "outputs = pd.read_csv('top_outputs.csv')\n",
    "X = torch.tensor(inputs.values)\n",
    "y = torch.tensor(outputs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"C:\\Data generation\\Dimethyl ether - Aspen HYSYS\\i-dme-complete-gsa-equil.hsc\"  # path to the hysys file\n",
    "file = filepath + r\"\\i-dme-complete-gsa-equil.hsc\"\n",
    "\n",
    "# Creating and connecting to the hysys flowsheet and solve\n",
    "try:\n",
    "    sim = hop.hysys_connection(file, active=1)\n",
    "except:\n",
    "    sim = hop.hysys_connection(file, active=0)\n",
    "\n",
    "fsheet = sim.Flowsheet\n",
    "solver = sim.Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BOUNDS\n",
    "# electricity prices - 2018-2023 https://tradingeconomics.com/united-kingdom/electricity-price\n",
    "elec_nom = 89.2 # GBP/MWh - 02 Jan 2024\n",
    "elec_nom *= 0.804354 # USD/MWh\n",
    "elec_nom /= 1000 # USD/kWh\n",
    "\n",
    "# For the nominal/range of the MeOH reactor size from van Dal 2013\n",
    "ref_co2_flow = 88e3 # kg/h CO2\n",
    "co2_flow = 28333.3620500565 # kg/h in simulation\n",
    "co2_ratio = co2_flow/ref_co2_flow\n",
    "ref_cat_mass = 44500 # kg catalyst\n",
    "cat_mass = ref_cat_mass*co2_ratio # kg catalyst in simulation\n",
    "void = 0.5\n",
    "density = 1775\n",
    "meoh_nominal_vol = cat_mass * (1/density) * (1/(1-void)) # m3\n",
    "\n",
    "bounds = [[2.4, 3.6],       # h2 ratio - +/-20% of stoich\n",
    "        [5000, 10000],    # meoh pressure - van-dal2013\n",
    "        [210, 270],       # meoh feed temp - van-dal2013\n",
    "        [0, 1],           # adiabatic/isothermal meoh\n",
    "        [0.95, 0.991],      # recycle ratio\n",
    "        [0.8*meoh_nominal_vol, 1.2*meoh_nominal_vol], # meoh reactor volume - van-dal2013 +/- 20%\n",
    "        #[250, 300],       # dme feed temperature - peinado2020    \n",
    "        #[1000, 2000],     # dme reaction pressure - peinado2020\n",
    "        #[0,1],            # feed vapour fraction meoh column\n",
    "        #[0,1],            # feed vapour fraction dme-meoh column\n",
    "        #[57*0.8, 57*1.2], # trays col 1 +/- 20% of nominal\n",
    "        #[17*0.8, 17*1.2], # trays col 2 +/- 20% of nominal\n",
    "        #[44/57*0.8, 44/57*1.2], # relative feed location col 1 +/- 20% of nominal\n",
    "        #[10/17*0.8, 10/17*1.2]  # relative feed location col 2 +/- 20% of nominal\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pass the gsa sample points to the flowsheet, solve it and then calculate the outputs\n",
    "def solve_flowsheet(fsheet, solver, inputs):\n",
    "    sim.Visible = False # hiding the simulation improves solve time\n",
    "    # Running the flowsheet\n",
    "    try:\n",
    "        out = hgu.solve_calc_flowsheet(fsheet, solver, inputs)\n",
    "    except:\n",
    "        out = [None, None, None, None, None, None]\n",
    "\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from gpytorch.kernels import MaternKernel, RBFKernel\n",
    "from botorch.models.transforms import Standardize\n",
    "\n",
    "\n",
    "\n",
    "def initialize_model(X, y, GP=None, state_dict=None, *GP_args, **GP_kwargs):\n",
    "    \"\"\"\n",
    "    Create GP model and fit it. The function also accepts\n",
    "    state_dict which is used as an initialization for the GP model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : torch.tensor, shape=(n_samples, dim)\n",
    "        Input values\n",
    "        \n",
    "    y : torch.tensor, shape=(n_samples,)\n",
    "        Output values\n",
    "        \n",
    "    GP : botorch.models.Model\n",
    "        GP model class\n",
    "        \n",
    "    state_dict : dict\n",
    "        GP model state dict\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    mll : gpytorch.mlls.MarginalLoglikelihood\n",
    "        Marginal loglikelihood\n",
    "    \n",
    "    gp : \n",
    "    \"\"\"\n",
    "\n",
    "    covar_module = MaternKernel(nu=2.5)\n",
    "\n",
    "\n",
    "    if GP is None:\n",
    "        GP = SingleTaskGP\n",
    "        \n",
    "    model = GP(X, y,  outcome_transform=Standardize(1), covar_module = covar_module, *GP_args, **GP_kwargs).to(X)\n",
    "\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    # load state dict if it is passed\n",
    "    if state_dict is not None:\n",
    "        model.load_state_dict(state_dict)\n",
    "    return mll, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "def bo_step(X, y, objective, bounds, GP=None, acquisition=None, q=1, state_dict=None, plot=False):\n",
    "    # Create GP model if not provided\n",
    "    if y is not None:\n",
    "        mll, gp = initialize_model(X, y, GP=GP, state_dict=state_dict)\n",
    "        fit_gpytorch_model(mll)\n",
    "    \n",
    "    # Create acquisition function\n",
    "    acquisition = acquisition(gp)\n",
    "    \n",
    "    # Optimize acquisition function if y is not None\n",
    "    if y is not None:\n",
    "        candidate = optimize_acqf(\n",
    "            acquisition, bounds=bounds, q=q, num_restarts=50, raw_samples=1024,\n",
    "        )\n",
    "\n",
    "        # Check if objective is not None before updating y\n",
    "        y_new = objective(candidate[0].squeeze())\n",
    "        print('y_new=', y_new)\n",
    "        if y_new is not None:\n",
    "            y = torch.cat([y, y_new])\n",
    "            X = torch.cat([X, candidate[0]])\n",
    "        else: \n",
    "            # Repeat until y_random is not None\n",
    "            while True:\n",
    "                X_random = torch.rand(6)\n",
    "                y_rand = objective(X_random)\n",
    "                if y_rand is not None:\n",
    "                    break\n",
    "            X = torch.cat([X, X_random.unsqueeze(0)])\n",
    "            y = torch.cat([y, y_rand])\n",
    "\n",
    "    if plot:\n",
    "        utils.plot_acquisition(acquisition, X, y, candidate)\n",
    "        \n",
    "    return X, y, gp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.utils.transforms import normalize, unnormalize\n",
    "\n",
    "def normalize_x(params, space):\n",
    "    bounds = torch.tensor([var['domain'] for var in space]).to(params).t()\n",
    "    params = normalize(params, bounds)\n",
    "    return params\n",
    "\n",
    "def unnormalize_x(params, space):\n",
    "    bounds = torch.tensor([var['domain'] for var in space]).to(params).t()\n",
    "    params = unnormalize(params, bounds)\n",
    "    return params\n",
    "\n",
    "def wrap_X(X, space):\n",
    "\n",
    "    def _wrap_row(row):\n",
    "        wrapped_row = {}\n",
    "        for i, x in enumerate(row):\n",
    "            wrapped_row[space[i]['name']] = x.item()\n",
    "        \n",
    "            if space[i]['type'] == 'discrete':\n",
    "                wrapped_row[space[i]['name']] = int(np.round(x.item()))\n",
    "        return wrapped_row\n",
    "    \n",
    "    wrapped_X = []\n",
    "    for i in range(X.shape[0]):\n",
    "        wrapped_X.append(_wrap_row(X[i]))\n",
    "        \n",
    "    return wrapped_X\n",
    "\n",
    "\n",
    "def unwrap_X(parameters, space):\n",
    "\n",
    "    X = torch.zeros(len(parameters), len(space),\n",
    "                    dtype=torch.float64)\n",
    "    for i, p in enumerate(parameters):\n",
    "        x = [p[var['name']] for var in space]\n",
    "        X[i] = torch.tensor(x, dtype=torch.float64)\n",
    "        \n",
    "    return X\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspen(p,space):\n",
    "    \n",
    "    #print(p)\n",
    "    p = unnormalize_x(p, space)\n",
    "    p = p.numpy()\n",
    "\n",
    "\n",
    "    #p_all = [3, 7800, 210, 0, 0.99, meoh_nominal_vol, 275, 1500, 0.5, 0.5, 57, 17, 44/57, 10/17]\n",
    "\n",
    "    p_all = [p[0], p[1], p[2], p[3], p[4], p[5], 275, 1500, 0.5, 0.5, 57, 17, 44/57, 10/17]\n",
    "\n",
    "    try:\n",
    "        out = solve_flowsheet(fsheet, solver, p_all)\n",
    "        print(out)\n",
    "    except:\n",
    "        try: # try open hysys and solve flowsheet once more if crashes\n",
    "            sim = hop.hysys_connection(file, active=0)\n",
    "            fsheet = sim.Flowsheet\n",
    "            solver = sim.Solver\n",
    "            out = solve_flowsheet(fsheet, solver, p_all)\n",
    "        except:\n",
    "            # if still crashes, open file again but skip this point\n",
    "            sim = hop.hysys_connection(file, active=0)\n",
    "            fsheet = sim.Flowsheet\n",
    "            solver = sim.Solver\n",
    "            out = [None, None, None, None, None, None]\n",
    "\n",
    "    if out[0] is None:\n",
    "        return None\n",
    "    else:\n",
    "        return torch.tensor(out[0]).unsqueeze(-1).unsqueeze(-1).to(torch.float64) #datatype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "\n",
    "# Define the region\n",
    "space = [\n",
    "    {'name': 'h2_ratio', 'type': 'continuous', 'domain': (2.4, 3.6)},\n",
    "    {'name': 'Pmeoh', 'type': 'continuous', 'domain': (5000, 10000)},\n",
    "    {'name': 'Tmeoh', 'type': 'continuous', 'domain': (210, 270)},\n",
    "    {'name': 'ad_is', 'type': 'continuous', 'domain': (0, 1)},\n",
    "    {'name': 'recycle_ratio', 'type': 'continuous', 'domain': (0.95, 0.991)},\n",
    "    {'name': 'Vtotal', 'type': 'continuous', 'domain': (0.8*meoh_nominal_vol, 1.2*meoh_nominal_vol)},\n",
    "    #{'name': 'Tdme', 'type': 'continuous', 'domain': (250, 300)},\n",
    "    #{'name': 'Pdme', 'type': 'continuous', 'domain': (1000, 2000)},\n",
    "    #{'name': 'Xmeoh', 'type': 'continuous', 'domain': (0, 1)},\n",
    "    #{'name': 'Xdme', 'type': 'continuous', 'domain': (0, 1)},\n",
    "    #{'name': 'trays1', 'type': 'continuous', 'domain': (57*0.8, 57*1.2)},\n",
    "    #{'name': 'trays2', 'type': 'continuous', 'domain': (17*0.8, 17*1.2)},\n",
    "    #{'name': 'feed_loc1', 'type': 'continuous', 'domain': (44/57*0.8, 44/57*1.2)}, \n",
    "    #{'name': 'feed_loc2', 'type': 'continuous', 'domain': (10/17*0.8, 10/17*1.2)}, \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bounds_01 = torch.zeros(2, len(space), dtype=torch.float64)\n",
    "bounds_01[1] = 1\n",
    "\n",
    "init_X = draw_sobol_samples(bounds_01, 6, 1).squeeze()\n",
    "\n",
    "init_y = []\n",
    "valid_init_X = []\n",
    "\n",
    "\n",
    "while len(init_y) < 5:\n",
    "    for i in range(len(init_X)):\n",
    "        result = aspen(init_X[i], space)\n",
    "        if result is not None:\n",
    "            init_y.append(result)\n",
    "            valid_init_X.append(init_X[i])\n",
    "    \n",
    "    # If len(init_y) is still less than 5, generate additional Sobol samples\n",
    "    if len(init_y) < 5:\n",
    "        additional_samples = draw_sobol_samples(bounds_01, 5 - len(init_y), 1).squeeze()\n",
    "        init_X = torch.cat([init_X, additional_samples])\n",
    "\n",
    "# Now init_X, init_y, and valid_init_X correspond to each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_y2= torch.tensor(init_y)\n",
    "init_y2= init_y2.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init_X2 = torch.stack(valid_init_X)\n",
    "init_X2 = torch.cat([normalize_x(X, space), init_X2])\n",
    "init_y2 = torch.cat([y, init_y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(params, scores, space):\n",
    "    bounds = torch.tensor([var['domain'] for var in space]).to(params).t()\n",
    "    params = unnormalize(params, bounds)\n",
    "    \n",
    "    best_idx = np.argmax(scores.cpu().numpy())\n",
    "    \n",
    "    return wrap_X(params[[best_idx]], space)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import (ExpectedImprovement, PosteriorMean,\n",
    "                                 ProbabilityOfImprovement,\n",
    "                                 UpperConfidenceBound, qKnowledgeGradient)\n",
    "from botorch.acquisition.max_value_entropy_search import qMaxValueEntropy\n",
    "from botorch.sampling import SobolQMCNormalSampler\n",
    "from botorch.acquisition.max_value_entropy_search import qMaxValueEntropy\n",
    "\n",
    "cum_best_df = pd.DataFrame()\n",
    "best_params_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(0, 100,10) :\n",
    "\n",
    "    print('Seed:', i, 'out of 100')\n",
    "\n",
    "    torch.manual_seed(i)\n",
    "\n",
    "\n",
    "\n",
    "    params = init_X2 \n",
    "\n",
    "    scores = init_y2\n",
    "\n",
    "    state_dict = None\n",
    "\n",
    "    budget = 116\n",
    "\n",
    "    objective = lambda x: aspen(x, space)\n",
    "\n",
    "    # Initialize the counter for consecutive iterations without improvement\n",
    "    no_improvement_count = 0\n",
    "    consecutive_iterations_threshold = 20  # Threshold for consecutive iterations without improvement\n",
    "\n",
    "    best_score = float('-inf')  # Initialize the best score to a very low number\n",
    "\n",
    "    with tqdm.tqdm(total=budget) as bar:\n",
    "        while len(scores) < budget:\n",
    "            n_samples = len(scores)\n",
    "        \n",
    "            # Assuming the rest of your optimization code goes here and updates `scores`\n",
    "            GP = SingleTaskGP\n",
    "        \n",
    "\n",
    "            acquisition = lambda gp: UpperConfidenceBound(gp, beta=15, maximize=True)\n",
    "        \n",
    "\n",
    "            params, scores, gp = bo_step(params, scores, objective, bounds_01,\n",
    "                                     GP=GP, acquisition=acquisition, \n",
    "                                     )\n",
    "            \n",
    "  \n",
    "            current_best_score = scores.max().item()  # Get the current best score\n",
    "        \n",
    "            # Check if there is an improvement\n",
    "            if current_best_score > best_score:\n",
    "                best_score = current_best_score  # Update the best score\n",
    "                no_improvement_count = 0  # Reset the counter since there was an improvement\n",
    "            else:\n",
    "                no_improvement_count += 1  # Increment the counter\n",
    "        \n",
    "            # Terminate if the number of consecutive iterations without improvement\n",
    "            # reaches the threshold\n",
    "            if no_improvement_count >= consecutive_iterations_threshold:\n",
    "                print(\"Termination criterion met: No improvement for 20 consecutive iterations.\")\n",
    "                break  # Terminate the loop\n",
    "        \n",
    "            bar.update(len(scores) - n_samples)\n",
    "\n",
    "\n",
    "        cum_best = np.maximum.accumulate(scores.cpu().numpy())\n",
    "\n",
    "        # Create a temporary DataFrame from `cum_best` and reindex `cum_best_df` to ensure it's long enough\n",
    "        temp_df = pd.DataFrame({f'{i}': cum_best.squeeze()})\n",
    "        cum_best_df = cum_best_df.reindex(index=range(max(len(cum_best_df), len(temp_df)))).assign(**temp_df)\n",
    "        best_param = get_best_params(params, scores, space)\n",
    "        best_param_values = list(best_param.values())\n",
    "        best_params_df[f'{i}'] = pd.Series(best_param_values)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================================RESULTS==============================================================\n",
    "\n",
    "for key, value in best_param.items():\n",
    "        print(f'{key}: {value}\\n')\n",
    "\n",
    "print('Optimum', scores.max().item())\n",
    "\n",
    "utils.plot_convergence(params, scores, maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cum_best = np.maximum.accumulate(scores.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nt_gsa_bo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
